<style>
/* Prevent page breaks inside elements */
pre, code, blockquote {
  page-break-inside: avoid;
}
table {
  page-break-inside: avoid;
}
/* Keep headings with following content */
h1, h2, h3, h4 {
  page-break-after: avoid;
}
</style>

# ğŸ  BÃO CÃO Ká»¸ THUáº¬T: Dá»° ÄOÃN GIÃ NHÃ€

## VietAI - Foundations of Machine Learning
### Final Project Report

---

**NgÃ y hoÃ n thÃ nh:** ThÃ¡ng 12/2025

**CÃ´ng nghá»‡ sá»­ dá»¥ng:** Python, Scikit-learn, PyTorch, FastAPI, Streamlit

---

## ğŸ“‘ Má»¤C Lá»¤C

1. [Giá»›i thiá»‡u bÃ i toÃ¡n](#1-giá»›i-thiá»‡u-bÃ i-toÃ¡n)
2. [PhÃ¢n tÃ­ch vÃ  khÃ¡m phÃ¡ dá»¯ liá»‡u](#2-phÃ¢n-tÃ­ch-vÃ -khÃ¡m-phÃ¡-dá»¯-liá»‡u)
3. [Pipeline xá»­ lÃ½ dá»¯ liá»‡u](#3-pipeline-xá»­-lÃ½-dá»¯-liá»‡u)
4. [Huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh](#4-huáº¥n-luyá»‡n-vÃ -Ä‘Ã¡nh-giÃ¡-mÃ´-hÃ¬nh)
5. [HÆ°á»›ng dáº«n sá»­ dá»¥ng](#5-hÆ°á»›ng-dáº«n-sá»­-dá»¥ng)
6. [Káº¿t luáº­n vÃ  hÆ°á»›ng phÃ¡t triá»ƒn](#6-káº¿t-luáº­n-vÃ -hÆ°á»›ng-phÃ¡t-triá»ƒn)

---

## 1. GIá»šI THIá»†U BÃ€I TOÃN

### 1.1 Tá»•ng quan

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t há»‡ thá»‘ng Machine Learning hoÃ n chá»‰nh Ä‘á»ƒ **dá»± Ä‘oÃ¡n giÃ¡ nhÃ ** dá»±a trÃªn cÃ¡c Ä‘áº·c Ä‘iá»ƒm cá»§a ngÃ´i nhÃ . Há»‡ thá»‘ng bao gá»“m tá»« viá»‡c xá»­ lÃ½ dá»¯ liá»‡u thÃ´, huáº¥n luyá»‡n mÃ´ hÃ¬nh, cho Ä‘áº¿n triá»ƒn khai sáº£n pháº©m Ä‘á»ƒ ngÆ°á»i dÃ¹ng cuá»‘i cÃ³ thá»ƒ tÆ°Æ¡ng tÃ¡c.

### 1.2 Dataset

- **Nguá»“n:** Kaggle - House Prices: Advanced Regression Techniques
- **URL:** https://www.kaggle.com/c/house-prices-advanced-regression-techniques
- **KÃ­ch thÆ°á»›c:** 
  - Training set: 1,460 samples
  - Test set: 1,459 samples
  - Features: 79 variables (36 numerical, 43 categorical)
- **Target variable:** `SalePrice` - GiÃ¡ bÃ¡n nhÃ  (USD)

### 1.3 Má»¥c tiÃªu dá»± Ã¡n

| Má»¥c tiÃªu                 | MÃ´ táº£                                  |
|--------------------------|----------------------------------------|
| **Data Validation**      | Kiá»ƒm Ä‘á»‹nh cháº¥t lÆ°á»£ng dá»¯ liá»‡u Ä‘áº§u vÃ o   |
| **Feature Engineering**  | Táº¡o Ä‘áº·c trÆ°ng má»›i Ä‘á»ƒ tá»‘i Æ°u hiá»‡u nÄƒng  |
| **Model Training**       | Huáº¥n luyá»‡n vÃ  so sÃ¡nh nhiá»u mÃ´ hÃ¬nh    |
| **API Deployment**       | Triá»ƒn khai mÃ´ hÃ¬nh dÆ°á»›i dáº¡ng REST API  |
| **Web Interface**        | XÃ¢y dá»±ng giao diá»‡n web tÆ°Æ¡ng tÃ¡c       |
| **Deep Learning**        | Thá»­ nghiá»‡m máº¡ng nÆ¡-ron vá»›i PyTorch     |

### 1.4 Cáº¥u trÃºc dá»± Ã¡n

```
Final project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Dá»¯ liá»‡u gá»‘c
â”‚   â””â”€â”€ processed/        # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA.ipynb      # Exploratory Data Analysis
â”‚   â””â”€â”€ 02_Training.ipynb # Model Training Pipeline
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py         # Cáº¥u hÃ¬nh
â”‚   â”œâ”€â”€ data_validation.py# Kiá»ƒm Ä‘á»‹nh dá»¯ liá»‡u
â”‚   â”œâ”€â”€ preprocessing.py  # Tiá»n xá»­ lÃ½
â”‚   â”œâ”€â”€ model_training.py # Huáº¥n luyá»‡n mÃ´ hÃ¬nh
â”‚   â””â”€â”€ deep_learning.py  # Neural Network (PyTorch)
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py           # FastAPI Backend
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py  # Streamlit Frontend
â”œâ”€â”€ models/               # MÃ´ hÃ¬nh Ä‘Ã£ lÆ°u
â”œâ”€â”€ reports/              # BÃ¡o cÃ¡o vÃ  biá»ƒu Ä‘á»“
â””â”€â”€ requirements.txt      # Dependencies
```

---

<div style="page-break-after: always;"></div>

## 2. PHÃ‚N TÃCH VÃ€ KHÃM PHÃ Dá»® LIá»†U

### 2.1 Thá»‘ng kÃª mÃ´ táº£

#### Target variable (SalePrice)

| Thá»‘ng kÃª  | GiÃ¡ trá»‹              |
|-----------|----------------------|
| Mean      | $180,921             |
| Median    | $163,000             |
| Std       | $79,443              |
| Min       | $34,900              |
| Max       | $755,000             |
| Skewness  | 1.88 (Right-skewed)  |

**Nháº­n xÃ©t:** PhÃ¢n phá»‘i giÃ¡ nhÃ  lá»‡ch pháº£i, cáº§n Ã¡p dá»¥ng **log transformation** Ä‘á»ƒ chuáº©n hÃ³a.

#### CÃ¡c biáº¿n sá»‘ quan trá»ng

| Feature      | Mean         | Std  | Min   | Max    |
|--------------|--------------|------|-------|--------|
| GrLivArea    | 1,515 sq ft  | 525  | 334   | 5,642  |
| OverallQual  | 6.1          | 1.4  | 1     | 10     |
| YearBuilt    | 1971         | 30   | 1872  | 2010   |
| TotalBsmtSF  | 1,057 sq ft  | 439  | 0     | 6,110  |
| GarageCars   | 1.8          | 0.7  | 0     | 4      |

### 2.2 PhÃ¢n tÃ­ch giÃ¡ trá»‹ thiáº¿u (Missing Values)

```
ğŸ“Š Columns with Missing Values: 19/81

Top Missing Columns:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Column          â”‚ Missing   â”‚ %       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PoolQC          â”‚ 1,453     â”‚ 99.5%   â”‚
â”‚ MiscFeature     â”‚ 1,406     â”‚ 96.3%   â”‚
â”‚ Alley           â”‚ 1,369     â”‚ 93.8%   â”‚
â”‚ Fence           â”‚ 1,179     â”‚ 80.8%   â”‚
â”‚ MasVnrType      â”‚ 872       â”‚ 59.7%   â”‚
â”‚ FireplaceQu     â”‚ 690       â”‚ 47.3%   â”‚
â”‚ LotFrontage     â”‚ 259       â”‚ 17.7%   â”‚
â”‚ GarageType      â”‚ 81        â”‚ 5.5%    â”‚
â”‚ BsmtQual        â”‚ 37        â”‚ 2.5%    â”‚
â”‚ BsmtCond        â”‚ 37        â”‚ 2.5%    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Chiáº¿n lÆ°á»£c xá»­ lÃ½:**
- **PoolQC, Alley, Fence, MiscFeature:** NA cÃ³ nghÄ©a "khÃ´ng cÃ³" â†’ Fill vá»›i "None"
- **LotFrontage:** Fill vá»›i median theo Neighborhood
- **Garage, Basement features:** NA nghÄ©a "khÃ´ng cÃ³" â†’ Fill vá»›i 0 hoáº·c "None"

### 2.3 PhÃ¢n tÃ­ch tÆ°Æ¡ng quan

#### Top 10 Features tÆ°Æ¡ng quan cao nháº¥t vá»›i SalePrice

| Rank | Feature       | Correlation |
|------|---------------|-------------|
| 1    | OverallQual   | 0.79        |
| 2    | GrLivArea     | 0.71        |
| 3    | GarageCars    | 0.64        |
| 4    | GarageArea    | 0.62        |
| 5    | TotalBsmtSF   | 0.61        |
| 6    | 1stFlrSF      | 0.61        |
| 7    | FullBath      | 0.56        |
| 8    | TotRmsAbvGrd  | 0.53        |
| 9    | YearBuilt     | 0.52        |
| 10   | YearRemodAdd  | 0.51        |

**Nháº­n xÃ©t:** 
- `OverallQual` vÃ  `GrLivArea` cÃ³ tÆ°Æ¡ng quan máº¡nh nháº¥t
- CÃ¡c features liÃªn quan Ä‘áº¿n diá»‡n tÃ­ch vÃ  cháº¥t lÆ°á»£ng lÃ  quan trá»ng nháº¥t

### 2.4 PhÃ¢n tÃ­ch Outliers

```
Outliers detected (IQR method):
- GrLivArea: 31 outliers
- SalePrice: 61 outliers
- LotArea: 113 outliers

Critical outliers to remove:
- 2 houses with GrLivArea > 4000 sq ft and SalePrice < $300,000
  (Unusual pattern - likely data entry errors)
```

### 2.5 Biá»ƒu Ä‘á»“ phÃ¢n tÃ­ch

*(CÃ¡c biá»ƒu Ä‘á»“ Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c `reports/`)*

1. **missing_values.png** - Heatmap giÃ¡ trá»‹ thiáº¿u
2. **target_distribution.png** - PhÃ¢n phá»‘i SalePrice (original vs log)
3. **correlation_heatmap.png** - Ma tráº­n tÆ°Æ¡ng quan top 15 features
4. **scatter_plots.png** - Scatter plots cÃ¡c features quan trá»ng
5. **categorical_analysis.png** - Box plots biáº¿n phÃ¢n loáº¡i

---

<div style="page-break-after: always;"></div>

## 3. PIPELINE Xá»¬ LÃ Dá»® LIá»†U

### 3.1 Tá»•ng quan Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw Data      â”‚â”€â”€â”€â”€â–¶â”‚  Data Validationâ”‚â”€â”€â”€â”€â–¶â”‚ Outlier Removal â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Training â”‚â—€â”€â”€â”€â”€â”‚  Feature Scalingâ”‚â—€â”€â”€â”€â”€â”‚Feature Engineer â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
                                                        â–¼
                                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                â”‚ Missing Values  â”‚
                                                â”‚ + Encoding      â”‚
                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Data Validation (Kiá»ƒm Ä‘á»‹nh dá»¯ liá»‡u)

**Schema Definition:**

```python
# Äá»‹nh nghÄ©a schema cho cÃ¡c cá»™t quan trá»ng
schema = {
    'OverallQual': {'type': 'numeric', 'min': 1, 'max': 10, 'nullable': False},
    'GrLivArea': {'type': 'numeric', 'min': 0, 'nullable': False},
    'YearBuilt': {'type': 'numeric', 'min': 1800, 'max': 2025, 'nullable': False},
    'Neighborhood': {'type': 'categorical', 'nullable': False},
    'ExterQual': {'type': 'categorical', 'values': ['Ex', 'Gd', 'TA', 'Fa', 'Po']},
    ...
}
```

**Data Quality Checks:**
- âœ… Kiá»ƒm tra kiá»ƒu dá»¯ liá»‡u
- âœ… Kiá»ƒm tra giÃ¡ trá»‹ null
- âœ… Kiá»ƒm tra khoáº£ng giÃ¡ trá»‹ há»£p lá»‡
- âœ… Kiá»ƒm tra giÃ¡ trá»‹ phÃ¢n loáº¡i há»£p lá»‡

### 3.3 Outlier Removal

```python
# Loáº¡i bá» outliers Ä‘áº·c biá»‡t (identified in EDA)
outlier_mask = (df['GrLivArea'] > 4000) & (df['SalePrice'] < 300000)
df_clean = df[~outlier_mask]

# Káº¿t quáº£: Loáº¡i bá» 2 outliers
# Training data: 1,460 â†’ 1,458 rows
```

### 3.4 Feature Engineering

#### CÃ¡c features má»›i Ä‘Æ°á»£c táº¡o (14 features):

| Feature           | CÃ´ng thá»©c                           | MÃ´ táº£                |
|-------------------|-------------------------------------|----------------------|
| TotalSF           | TotalBsmtSF + 1stFlrSF + 2ndFlrSF   | Tá»•ng diá»‡n tÃ­ch       |
| TotalBath         | FullBath + 0.5Ã—Half + BsmtFull...   | Tá»•ng sá»‘ phÃ²ng táº¯m    |
| TotalPorchSF      | WoodDeck + OpenPorch + Enclosed...  | Tá»•ng diá»‡n tÃ­ch hiÃªn  |
| HouseAge          | YrSold - YearBuilt                  | Tuá»•i nhÃ              |
| RemodAge          | YrSold - YearRemodAdd               | Thá»i gian tá»« cáº£i táº¡o |
| WasRemodeled      | YearRemodAdd â‰  YearBuilt ? 1 : 0    | ÄÃ£ cáº£i táº¡o?          |
| HasPool           | PoolArea > 0 ? 1 : 0                | CÃ³ há»“ bÆ¡i?           |
| HasGarage         | GarageArea > 0 ? 1 : 0              | CÃ³ garage?           |
| HasFireplace      | Fireplaces > 0 ? 1 : 0              | CÃ³ lÃ² sÆ°á»Ÿi?          |
| HasBasement       | TotalBsmtSF > 0 ? 1 : 0             | CÃ³ táº§ng háº§m?         |
| Has2ndFloor       | 2ndFlrSF > 0 ? 1 : 0                | CÃ³ táº§ng 2?           |
| QualityArea       | OverallQual Ã— GrLivArea             | Cháº¥t lÆ°á»£ng Ã— DT      |
| OverallScore      | OverallQual Ã— OverallCond           | Äiá»ƒm tá»•ng thá»ƒ        |
| GarageEfficiency  | GarageCars / (GarageArea + 1)       | Hiá»‡u suáº¥t garage     |

### 3.5 Missing Value Handling

```python
# Chiáº¿n lÆ°á»£c xá»­ lÃ½ giÃ¡ trá»‹ thiáº¿u

# 1. Columns cÃ³ NA nghÄ©a "khÃ´ng cÃ³ feature"
NONE_FILL_COLS = ['Alley', 'PoolQC', 'Fence', 'MiscFeature', 'FireplaceQu',
                  'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',
                  'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']
â†’ Fill vá»›i 'None'

# 2. Numerical columns
â†’ Fill vá»›i median

# 3. Categorical columns khÃ¡c
â†’ Fill vá»›i mode
```

**Káº¿t quáº£:** Missing values: 7,829 â†’ 0

### 3.6 Categorical Encoding

#### Quality Mapping (Ordinal Encoding):

```python
QUALITY_MAPPING = {
    'Ex': 5,   # Excellent
    'Gd': 4,   # Good
    'TA': 3,   # Typical/Average
    'Fa': 2,   # Fair
    'Po': 1,   # Poor
    'None': 0  # No feature
}

# Ãp dá»¥ng cho: ExterQual, ExterCond, BsmtQual, BsmtCond,
#              HeatingQC, KitchenQual, FireplaceQu, GarageQual, GarageCond, PoolQC
```

#### One-Hot Encoding:

```python
# CÃ¡c biáº¿n phÃ¢n loáº¡i cÃ²n láº¡i
X = pd.get_dummies(X, drop_first=True)

# Káº¿t quáº£: 79 features â†’ 241 features sau encoding
```

### 3.7 Feature Scaling

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Xá»­ lÃ½ NaN/Inf sau scaling
X_train_scaled = np.nan_to_num(X_train_scaled, nan=0.0, posinf=0.0, neginf=0.0)
```

### 3.8 Target Transformation

```python
# Log transformation cho SalePrice (giáº£m skewness)
y = np.log1p(df['SalePrice'])

# Khi dá»± Ä‘oÃ¡n, convert ngÆ°á»£c:
predicted_price = np.expm1(prediction_log)
```

---

<div style="page-break-after: always;"></div>

## 4. HUáº¤N LUYá»†N VÃ€ ÄÃNH GIÃ MÃ” HÃŒNH

### 4.1 Train-Test Split

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    random_state=42
)

# Káº¿t quáº£:
# Training set: 1,166 samples
# Test set: 292 samples
```

### 4.2 CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n

#### Traditional Machine Learning:

| Model              | Hyperparameters                       |
|--------------------|---------------------------------------|
| Linear Regression  | Default                               |
| Ridge Regression   | alpha=10.0                            |
| Lasso Regression   | alpha=0.001, max_iter=10000           |
| ElasticNet         | alpha=0.001, l1_ratio=0.5             |
| Random Forest      | n_estimators=100, random_state=42     |
| Gradient Boosting  | n_estimators=100, random_state=42     |

#### Deep Learning (Bonus):

```python
# PyTorch Neural Network Architecture
HousePriceNN(
    Input(241) 
    â†’ Linear(256) â†’ BatchNorm â†’ ReLU â†’ Dropout(0.3)
    â†’ Linear(128) â†’ BatchNorm â†’ ReLU â†’ Dropout(0.2)
    â†’ Linear(64)  â†’ BatchNorm â†’ ReLU â†’ Dropout(0.1)
    â†’ Linear(32)  â†’ ReLU
    â†’ Linear(1)   # Output
)

# Training config:
# - Optimizer: Adam (lr=0.001)
# - Loss: MSELoss
# - Epochs: 100 (with early stopping, patience=15)
# - Batch size: 32
```

### 4.3 Metrics Ä‘Ã¡nh giÃ¡

| Metric       | CÃ´ng thá»©c              | Ã nghÄ©a                    |
|--------------|------------------------|----------------------------|
| **MAE**      | Î£\|y - Å·\| / n         | Sai sá»‘ trung bÃ¬nh tuyá»‡t Ä‘á»‘i |
| **MSE**      | Î£(y - Å·)Â² / n          | Sai sá»‘ bÃ¬nh phÆ°Æ¡ng TB      |
| **RMSE**     | âˆšMSE                   | CÄƒn báº­c hai MSE            |
| **RÂ² Score** | 1 - SS_res/SS_tot      | Há»‡ sá»‘ xÃ¡c Ä‘á»‹nh (0-1)       |
| **CV RÂ²**    | Cross-val RÂ² (5-fold)  | ÄÃ¡nh giÃ¡ Ä‘á»™ á»•n Ä‘á»‹nh        |

### 4.4 Káº¿t quáº£ so sÃ¡nh mÃ´ hÃ¬nh

#### Báº£ng káº¿t quáº£ chi tiáº¿t:

| Model              | Train RÂ² | Test RÂ²    | RMSE    | MAE ($)    | CV RÂ²    |
|--------------------|----------|------------|---------|------------|----------|
| **ElasticNet**     | 0.9471   | **0.9097** | 0.1234  | $14,608    | 0.9031   |
| Lasso              | 0.9447   | 0.9067     | 0.1254  | $14,387    | 0.9075   |
| Gradient Boosting  | 0.9653   | 0.9058     | 0.1260  | $14,457    | 0.9067   |
| Ridge              | 0.9484   | 0.9047     | 0.1268  | $15,180    | 0.8961   |
| Random Forest      | 0.9841   | 0.8821     | 0.1410  | $15,944    | 0.8825   |
| Linear Regression  | 0.9496   | -6.2e14*   | 1.0e7*  | $8.3M*     | Unstable |
| Neural Network     | -        | 0.4255     | 0.3112  | $42,846    | -        |

*Linear Regression bá»‹ multicollinearity, khÃ´ng á»•n Ä‘á»‹nh.

#### Biá»ƒu Ä‘á»“ so sÃ¡nh:

```
Model Performance (Test RÂ²)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ElasticNet       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 0.91
Lasso            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–“ 0.91
Gradient Boost   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–“ 0.91
Ridge            â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 0.90
Random Forest    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 0.88
Neural Network   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.43
```

### 4.5 Best Model Selection

```
ğŸ† BEST MODEL: ElasticNet

LÃ½ do lá»±a chá»n:
âœ… Test RÂ² cao nháº¥t: 0.9097
âœ… RMSE tháº¥p nháº¥t: 0.1234
âœ… CV RÂ² á»•n Ä‘á»‹nh: 0.9031 (Â±0.0266)
âœ… Regularization (L1+L2) chá»‘ng overfitting
âœ… MAE cháº¥p nháº­n Ä‘Æ°á»£c: $14,608
```

### 4.6 PhÃ¢n tÃ­ch Neural Network

**Táº¡i sao Neural Network performkÃ©m hÆ¡n?**

1. **Dataset quÃ¡ nhá»:** 1,166 samples khÃ´ng Ä‘á»§ cho deep learning
2. **BÃ i toÃ¡n tuyáº¿n tÃ­nh:** Quan há»‡ giá»¯a features vÃ  price gáº§n nhÆ° tuyáº¿n tÃ­nh
3. **Feature engineering tá»‘t:** Linear models táº­n dá»¥ng tá»‘t hÆ¡n
4. **Overfitting:** 70,000+ parameters cho 1,166 samples

---

<div style="page-break-after: always;"></div>

## 5. HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG

### 5.1 CÃ i Ä‘áº·t mÃ´i trÆ°á»ng

```bash
# Clone repository
git clone <repository_url>
cd "Final project"

# Táº¡o virtual environment
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c: venv\Scripts\activate  # Windows

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

### 5.2 Cháº¡y Notebooks

```bash
# EDA Notebook
jupyter notebook notebooks/01_EDA.ipynb

# Training Notebook
jupyter notebook notebooks/02_Training.ipynb
```

### 5.3 Khá»Ÿi Ä‘á»™ng API Server

```bash
cd api
uvicorn main:app --reload --port 8000

# API sáº½ cháº¡y táº¡i: http://localhost:8000
# Documentation: http://localhost:8000/docs
```

#### API Endpoints:

| Method | Endpoint       | MÃ´ táº£                   |
|--------|----------------|-------------------------|
| GET    | `/health`      | Kiá»ƒm tra tráº¡ng thÃ¡i API |
| GET    | `/model-info`  | ThÃ´ng tin mÃ´ hÃ¬nh       |
| GET    | `/features`    | Danh sÃ¡ch features      |
| POST   | `/predict`     | Dá»± Ä‘oÃ¡n giÃ¡ nhÃ          |

#### VÃ­ dá»¥ request:

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "OverallQual": 7,
    "GrLivArea": 1500,
    "YearBuilt": 2005,
    "YearRemodAdd": 2005,
    "FullBath": 2,
    "TotRmsAbvGrd": 7,
    "TotalBsmtSF": 1000,
    "GarageCars": 2,
    "GarageArea": 500
  }'
```

#### Response:

```json
{
  "predicted_price": 186500.00,
  "predicted_price_formatted": "$186,500",
  "confidence_interval": {
    "lower": 158525.00,
    "upper": 214475.00,
    "formatted": "$158,525 - $214,475"
  },
  "model_info": {
    "model_name": "ElasticNet",
    "test_r2": 0.9097
  }
}
```

### 5.4 Khá»Ÿi Ä‘á»™ng Web App

```bash
cd app
streamlit run streamlit_app.py

# Web App sáº½ cháº¡y táº¡i: http://localhost:8501
```

#### TÃ­nh nÄƒng Web App:

- ğŸ“ Form nháº­p thÃ´ng tin nhÃ 
- ğŸ”® Dá»± Ä‘oÃ¡n giÃ¡ nhÃ  real-time
- ğŸ“Š Hiá»ƒn thá»‹ gauge chart vÃ  confidence interval
- ğŸ“‹ TÃ³m táº¯t thÃ´ng tin Ä‘Ã£ nháº­p

### 5.5 Quick Start Script

```bash
# Cháº¡y script tá»± Ä‘á»™ng
./run.sh

# Chá»n option:
# 1) Run EDA Notebook
# 2) Run Training Notebook
# 3) Start API Server
# 4) Start Streamlit App
# 5) Start Both API and Streamlit
# 6) Exit
```

---

<div style="page-break-after: always;"></div>

## 6. Káº¾T LUáº¬N VÃ€ HÆ¯á»šNG PHÃT TRIá»‚N

### 6.1 Káº¿t luáº­n

#### Nhá»¯ng gÃ¬ Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c:

âœ… **Data Pipeline hoÃ n chá»‰nh:**
- Data validation vá»›i schema checking
- Feature engineering (14 features má»›i)
- Missing value handling
- Outlier detection vÃ  removal

âœ… **Model Training:**
- So sÃ¡nh 6 models traditional ML
- Thá»­ nghiá»‡m Deep Learning vá»›i PyTorch
- ElasticNet Ä‘áº¡t RÂ² = 0.9097

âœ… **Deployment:**
- FastAPI backend RESTful API
- Streamlit frontend interactive
- Error handling vÃ  logging

âœ… **Code Quality:**
- Modular architecture (src/, api/, app/)
- Type hints vÃ  documentation
- Consistent coding style

#### Key Insights:

1. **Feature Engineering quan trá»ng:** TotalSF, QualityArea lÃ  features máº¡nh nháº¥t
2. **Linear models phÃ¹ há»£p:** Vá»›i dataset nhá» vÃ  bÃ i toÃ¡n tuyáº¿n tÃ­nh
3. **Regularization cáº§n thiáº¿t:** ElasticNet outperform Linear Regression
4. **Deep Learning khÃ´ng phÃ¹ há»£p:** Dataset quÃ¡ nhá» cho neural networks

### 6.2 Háº¡n cháº¿

| Háº¡n cháº¿              | MÃ´ táº£                                     |
|----------------------|-------------------------------------------|
| Dataset nhá»          | Chá»‰ 1,460 samples, háº¡n cháº¿ deep learning  |
| Äá»‹a Ä‘iá»ƒm cá»¥ thá»ƒ      | Chá»‰ Ã¡p dá»¥ng cho Ames, Iowa                |
| Temporal limitation  | Data tá»« 2006-2010, cÃ³ thá»ƒ outdated        |
| Missing features     | KhÃ´ng cÃ³ info trÆ°á»ng há»c, crime rate      |

### 6.3 HÆ°á»›ng phÃ¡t triá»ƒn tÆ°Æ¡ng lai

#### Ngáº¯n háº¡n:

- [ ] Hyperparameter tuning vá»›i GridSearchCV/Optuna
- [ ] Ensemble methods (Stacking, Voting)
- [ ] Feature selection (RFE, LASSO path)
- [ ] Cross-validation strategies (Stratified K-Fold)

#### Trung háº¡n:

- [ ] ThÃªm external data (school ratings, crime statistics)
- [ ] Time series features (housing market trends)
- [ ] Geospatial features (distance to amenities)
- [ ] A/B testing framework

#### DÃ i háº¡n:

- [ ] Triá»ƒn khai production vá»›i Docker/Kubernetes
- [ ] Monitoring vÃ  model retraining pipeline
- [ ] Expand sang cÃ¡c thÃ nh phá»‘ khÃ¡c
- [ ] Mobile application

### 6.4 BÃ i há»c kinh nghiá»‡m

> **"Simple models often outperform complex ones on small datasets."**

1. **Understand your data first:** EDA lÃ  bÆ°á»›c quan trá»ng nháº¥t
2. **Feature engineering > Model complexity:** Äáº§u tÆ° vÃ o features
3. **Regularization prevents overfitting:** LuÃ´n sá»­ dá»¥ng regularization
4. **Validate with cross-validation:** Äá»«ng chá»‰ dá»±a vÃ o train/test split
5. **Deep Learning needs big data:** KhÃ´ng pháº£i lÃºc nÃ o cÅ©ng lÃ  solution

---

## ğŸ“š TÃ€I LIá»†U THAM KHáº¢O

1. Kaggle House Prices Competition: https://www.kaggle.com/c/house-prices-advanced-regression-techniques
2. Scikit-learn Documentation: https://scikit-learn.org/stable/
3. FastAPI Documentation: https://fastapi.tiangolo.com/
4. Streamlit Documentation: https://docs.streamlit.io/
5. PyTorch Documentation: https://pytorch.org/docs/

---

## ğŸ“ PHá»¤ Lá»¤C

### A. Danh sÃ¡ch dependencies

```
pandas>=2.3.0
numpy>=2.4.0
scikit-learn>=1.8.0
torch>=2.9.0
fastapi>=0.128.0
streamlit>=1.52.0
```

### B. Hardware requirements

- **Minimum:** 4GB RAM, 2-core CPU
- **Recommended:** 8GB RAM, 4-core CPU, GPU (optional for PyTorch)

### C. Thá»i gian thá»±c thi

| Task                          | Thá»i gian  |
|-------------------------------|------------|
| Data loading                  | ~1s        |
| Preprocessing                 | ~2s        |
| Model training (all models)   | ~30s       |
| Neural Network (PyTorch)      | ~2-5 min   |
| API response                  | <100ms     |

---

**Â© 2025 VietAI - Foundations of Machine Learning**

*BÃ¡o cÃ¡o nÃ y Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng tá»« káº¿t quáº£ phÃ¢n tÃ­ch vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh.*
